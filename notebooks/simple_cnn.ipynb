{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GpfdjqTZlDRQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d018d960-57ed-46c1-ca95-05b3da0635d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.11)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.29.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.14.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb"
      ],
      "metadata": {
        "id": "MN4q_8mWLwF-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "X8ROGEdrLzpo",
        "outputId": "96ff9f5c-e2bf-4373-c560-c99a0b96d3ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnipkha21\u001b[0m (\u001b[33mnipkha21-free-university-of-tbilisi-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4tTypGWrL1iW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLbASSuzpV4J",
        "outputId": "a2927493-0ea0-4f28-ac4e-1e0c64c9ed8c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2"
      ],
      "metadata": {
        "id": "hE3VJyaPpjUU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from data_utils import load_split_data\n",
        "from models import SimpleCNN, get_model\n",
        "from training_utils import ModelTrainer, get_optimizer, get_scheduler\n",
        "from evaluation import ModelEvaluator"
      ],
      "metadata": {
        "id": "xBlXWvH_ppT_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "zonS4rtypyWZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNFacialExpressionDataset(Dataset):\n",
        "    def __init__(self, data, transform=None, augment=False, is_test=False):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "        self.augment = augment\n",
        "        self.is_test = is_test\n",
        "\n",
        "        if transform is None:\n",
        "            if augment and not is_test:\n",
        "                self.transform = self._get_augmentation_transform()\n",
        "            else:\n",
        "                self.transform = self._get_basic_transform()\n",
        "\n",
        "    def _get_basic_transform(self):\n",
        "        return A.Compose([\n",
        "            A.Normalize(mean=[0.485], std=[0.229]),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "\n",
        "    def _get_augmentation_transform(self):\n",
        "        return A.Compose([\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.Rotate(limit=15, p=0.3, border_mode=cv2.BORDER_CONSTANT, value=0),\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.3),\n",
        "            A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),\n",
        "            A.Blur(blur_limit=3, p=0.1),\n",
        "            A.CoarseDropout(max_holes=1, max_height=8, max_width=8,\n",
        "                           min_holes=1, min_height=4, min_width=4, p=0.2),\n",
        "            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=10, p=0.3),\n",
        "            A.Normalize(mean=[0.485], std=[0.229]),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pixels = self.data.iloc[idx]['pixels']\n",
        "        image = np.array([int(pixel) for pixel in pixels.split()]).reshape(48, 48)\n",
        "\n",
        "        image = np.stack([image] * 3, axis=-1).astype(np.uint8)\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image)\n",
        "            image = augmented['image']\n",
        "        else:\n",
        "            image = torch.FloatTensor(image).unsqueeze(0) / 255.0\n",
        "\n",
        "        if self.is_test:\n",
        "            return image\n",
        "        else:\n",
        "            emotion = int(self.data.iloc[idx]['emotion'])\n",
        "            return image, emotion"
      ],
      "metadata": {
        "id": "aynFXk90pvZ1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImprovedSimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=7, dropout_rate=0.3, use_batch_norm=True):\n",
        "        super(ImprovedSimpleCNN, self).__init__()\n",
        "\n",
        "        self.use_batch_norm = use_batch_norm\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32) if use_batch_norm else nn.Identity()\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64) if use_batch_norm else nn.Identity()\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128) if use_batch_norm else nn.Identity()\n",
        "\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256) if use_batch_norm else nn.Identity()\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((3, 3))\n",
        "\n",
        "        self.fc1 = nn.Linear(256 * 3 * 3, 512)\n",
        "        self.dropout1 = nn.Dropout(dropout_rate)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.dropout2 = nn.Dropout(dropout_rate / 2)\n",
        "        self.fc3 = nn.Linear(128, num_classes)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.shape[1] == 3:\n",
        "            x = x[:, 0:1, :, :]\n",
        "\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
        "\n",
        "        x = self.adaptive_pool(x)\n",
        "\n",
        "        x = x.view(-1, 256 * 3 * 3)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "aLZUH7CnpwLW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNTrainer:\n",
        "    def __init__(self, model, train_loader, val_loader, criterion, optimizer,\n",
        "                 scheduler=None, device='cuda', experiment_name='experiment', run_name='run'):\n",
        "        self.model = model.to(device)\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.device = device\n",
        "\n",
        "        wandb.init(\n",
        "            project=\"facial-expression-recognition\",\n",
        "            group=experiment_name,\n",
        "            name=run_name,\n",
        "            config={\n",
        "                \"data_split_method\": \"predefined_stratified\",\n",
        "                \"train_samples\": len(train_loader.dataset),\n",
        "                \"val_samples\": len(val_loader.dataset),\n",
        "                \"split_random_state\": 42\n",
        "            },\n",
        "            reinit=True\n",
        "        )\n",
        "        wandb.watch(self.model, log='all', log_freq=100)\n",
        "\n",
        "        self.history = {\n",
        "            'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [],\n",
        "            'learning_rates': [], 'epoch_times': []\n",
        "        }\n",
        "        self.best_val_acc = 0.0\n",
        "        self.best_model_state = None\n",
        "\n",
        "    def train_epoch(self):\n",
        "        self.model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        pbar = tqdm(self.train_loader, desc=\"Training\")\n",
        "        for batch_idx, (data, targets) in enumerate(pbar):\n",
        "            data, targets = data.to(self.device), targets.to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(data)\n",
        "            loss = self.criterion(outputs, targets)\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "            pbar.set_postfix({\n",
        "                'Loss': f'{loss.item():.4f}',\n",
        "                'Acc': f'{100.*correct/total:.2f}%'\n",
        "            })\n",
        "\n",
        "        epoch_loss = running_loss / len(self.train_loader)\n",
        "        epoch_acc = 100. * correct / total\n",
        "\n",
        "        return epoch_loss, epoch_acc\n",
        "\n",
        "    def validate_epoch(self):\n",
        "        self.model.eval()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_predictions = []\n",
        "        all_targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, targets in tqdm(self.val_loader, desc=\"Validation\"):\n",
        "                data, targets = data.to(self.device), targets.to(self.device)\n",
        "\n",
        "                outputs = self.model(data)\n",
        "                loss = self.criterion(outputs, targets)\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += targets.size(0)\n",
        "                correct += (predicted == targets).sum().item()\n",
        "\n",
        "                all_predictions.extend(predicted.cpu().numpy())\n",
        "                all_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "        epoch_loss = running_loss / len(self.val_loader)\n",
        "        epoch_acc = 100. * correct / total\n",
        "\n",
        "        return epoch_loss, epoch_acc, np.array(all_predictions), np.array(all_targets)\n",
        "\n",
        "    def train(self, epochs, early_stopping_patience=10):\n",
        "        print(f\"Starting CNN training for {epochs} epochs...\")\n",
        "\n",
        "        patience_counter = 0\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            epoch_start = time.time()\n",
        "\n",
        "            train_loss, train_acc = self.train_epoch()\n",
        "\n",
        "            val_loss, val_acc, val_preds, val_targets = self.validate_epoch()\n",
        "\n",
        "            current_lr = self.optimizer.param_groups[0]['lr']\n",
        "            if self.scheduler:\n",
        "                if isinstance(self.scheduler, ReduceLROnPlateau):\n",
        "                    self.scheduler.step(val_loss)\n",
        "                else:\n",
        "                    self.scheduler.step()\n",
        "\n",
        "            if val_acc > self.best_val_acc:\n",
        "                self.best_val_acc = val_acc\n",
        "                self.best_model_state = self.model.state_dict().copy()\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            epoch_time = time.time() - epoch_start\n",
        "\n",
        "            self.history['train_loss'].append(train_loss)\n",
        "            self.history['train_acc'].append(train_acc)\n",
        "            self.history['val_loss'].append(val_loss)\n",
        "            self.history['val_acc'].append(val_acc)\n",
        "            self.history['learning_rates'].append(current_lr)\n",
        "            self.history['epoch_times'].append(epoch_time)\n",
        "\n",
        "            log_dict = {\n",
        "                'epoch': epoch + 1,\n",
        "                'train_loss': train_loss,\n",
        "                'train_accuracy': train_acc,\n",
        "                'val_loss': val_loss,\n",
        "                'val_accuracy': val_acc,\n",
        "                'learning_rate': current_lr,\n",
        "                'epoch_time': epoch_time,\n",
        "                'best_val_accuracy': self.best_val_acc\n",
        "            }\n",
        "\n",
        "            if (epoch + 1) % 15 == 0:\n",
        "                emotion_map = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n",
        "                log_dict['confusion_matrix'] = wandb.plot.confusion_matrix(\n",
        "                    probs=None, y_true=val_targets, preds=val_preds,\n",
        "                    class_names=list(emotion_map.values())\n",
        "                )\n",
        "\n",
        "            wandb.log(log_dict)\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{epochs}:\")\n",
        "            print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "            print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "            print(f\"  LR: {current_lr:.6f}, Time: {epoch_time:.2f}s\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "            if patience_counter >= early_stopping_patience:\n",
        "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        if self.best_model_state:\n",
        "            self.model.load_state_dict(self.best_model_state)\n",
        "            print(f\"Loaded best model with validation accuracy: {self.best_val_acc:.2f}%\")\n",
        "\n",
        "        return self.history"
      ],
      "metadata": {
        "id": "gLu3o2LnpwNj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()\n",
        "\n",
        "print(\"=== LOADING PRE-SPLIT DATA ===\")\n",
        "\n",
        "train_df, val_df, test_df = load_split_data('drive/MyDrive/data')\n",
        "\n",
        "emotion_map = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Eoz1K0NpwQI",
        "outputId": "4d577c60-79ff-4d46-b82c-d89f59076c51"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== LOADING PRE-SPLIT DATA ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== DATA AUGMENTATION EXPERIMENTS ===\")\n",
        "\n",
        "augmentation_strategies = {\n",
        "    'no_augmentation': {\n",
        "        'augment': False,\n",
        "        'description': 'No data augmentation'\n",
        "    },\n",
        "    'basic_augmentation': {\n",
        "        'augment': True,\n",
        "        'transform': A.Compose([\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.Rotate(limit=10, p=0.3),\n",
        "            A.Normalize(mean=[0.485], std=[0.229]),\n",
        "            ToTensorV2()\n",
        "        ]),\n",
        "        'description': 'Basic: Flip + Rotation'\n",
        "    },\n",
        "    'advanced_augmentation': {\n",
        "        'augment': True,\n",
        "        'transform': A.Compose([\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.Rotate(limit=15, p=0.3),\n",
        "            A.RandomBrightnessContrast(p=0.3),\n",
        "            A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),\n",
        "            A.Normalize(mean=[0.485], std=[0.229]),\n",
        "            ToTensorV2()\n",
        "        ]),\n",
        "        'description': 'Advanced: Flip + Rotation + Brightness + Noise'\n",
        "    },\n",
        "    'heavy_augmentation': {\n",
        "        'augment': True,\n",
        "        'transform': A.Compose([\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.Rotate(limit=20, p=0.4),\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.4),\n",
        "            A.GaussNoise(var_limit=(10.0, 80.0), p=0.3),\n",
        "            A.Blur(blur_limit=3, p=0.2),\n",
        "            A.CoarseDropout(max_holes=2, max_height=8, max_width=8, p=0.3),\n",
        "            A.Normalize(mean=[0.485], std=[0.229]),\n",
        "            ToTensorV2()\n",
        "        ]),\n",
        "        'description': 'Heavy: All augmentations'\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_laEmaRpwTB",
        "outputId": "a6a4970e-e17c-47fa-d15d-7816db8d3aec"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== DATA AUGMENTATION EXPERIMENTS ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-30e62e1c36ca>:24: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
            "  A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),\n",
            "<ipython-input-15-30e62e1c36ca>:36: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
            "  A.GaussNoise(var_limit=(10.0, 80.0), p=0.3),\n",
            "<ipython-input-15-30e62e1c36ca>:38: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout\n",
            "  A.CoarseDropout(max_holes=2, max_height=8, max_width=8, p=0.3),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmentation_results = {}\n",
        "\n",
        "for aug_name, aug_config in augmentation_strategies.items():\n",
        "    print(f\"\\nTesting augmentation strategy: {aug_name}\")\n",
        "    print(f\"Description: {aug_config['description']}\")\n",
        "\n",
        "    if 'transform' in aug_config:\n",
        "        train_dataset = CNNFacialExpressionDataset(\n",
        "            train_df, transform=aug_config['transform'], augment=False\n",
        "        )\n",
        "        val_dataset = CNNFacialExpressionDataset(\n",
        "            val_df, transform=A.Compose([\n",
        "                A.Normalize(mean=[0.485], std=[0.229]),\n",
        "                ToTensorV2()\n",
        "            ]), augment=False\n",
        "        )\n",
        "    else:\n",
        "        train_dataset = CNNFacialExpressionDataset(\n",
        "            train_df, augment=aug_config['augment']\n",
        "        )\n",
        "        val_dataset = CNNFacialExpressionDataset(\n",
        "            val_df, augment=False\n",
        "        )\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "    model = SimpleCNN(num_classes=7, dropout_rate=0.5)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    trainer = CNNTrainer(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        criterion=criterion,\n",
        "        optimizer=optimizer,\n",
        "        device=device,\n",
        "        experiment_name=\"Simple_CNN_Training\",\n",
        "        run_name=f\"Augmentation_{aug_name}\"\n",
        "    )\n",
        "\n",
        "    history = trainer.train(epochs=1, early_stopping_patience=5)\n",
        "\n",
        "    augmentation_results[aug_name] = {\n",
        "        'best_val_acc': trainer.best_val_acc,\n",
        "        'final_train_acc': history['train_acc'][-1],\n",
        "        'final_val_acc': history['val_acc'][-1],\n",
        "        'overfitting_score': history['train_acc'][-1] - history['val_acc'][-1]\n",
        "    }\n",
        "\n",
        "    wandb.finish()\n",
        "\n",
        "    print(f\"Best validation accuracy: {trainer.best_val_acc:.2f}%\")\n",
        "\n",
        "print(\"\\n=== AUGMENTATION ANALYSIS ===\")\n",
        "best_augmentation = max(augmentation_results.keys(),\n",
        "                       key=lambda x: augmentation_results[x]['best_val_acc'])\n",
        "print(f\"Best augmentation strategy: {best_augmentation}\")\n",
        "\n",
        "for aug_name, results in augmentation_results.items():\n",
        "    print(f\"{aug_name}: {results['best_val_acc']:.2f}% \"\n",
        "          f\"(overfitting: {results['overfitting_score']:.2f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JXE-phYJpwU7",
        "outputId": "0d0536b9-b5ef-4648-f5ce-a517b080c9ce"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing augmentation strategy: no_augmentation\n",
            "Description: No data augmentation\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to True."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Augmentation_no_augmentation</strong> at: <a href='https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition/runs/avfqmjcp' target=\"_blank\">https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition/runs/avfqmjcp</a><br> View project at: <a href='https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition' target=\"_blank\">https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_185623-avfqmjcp/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_185648-zqqj8ddj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition/runs/zqqj8ddj' target=\"_blank\">Augmentation_no_augmentation</a></strong> to <a href='https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition' target=\"_blank\">https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition/runs/zqqj8ddj' target=\"_blank\">https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition/runs/zqqj8ddj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting CNN training for 1 epochs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 314/314 [02:01<00:00,  2.59it/s, Loss=1.5671, Acc=36.61%]\n",
            "Validation: 100%|██████████| 68/68 [00:12<00:00,  5.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1:\n",
            "  Train Loss: 1.6160, Train Acc: 36.61%\n",
            "  Val Loss: 1.4004, Val Acc: 47.30%\n",
            "  LR: 0.001000, Time: 133.57s\n",
            "--------------------------------------------------\n",
            "Loaded best model with validation accuracy: 47.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>epoch_time</td><td>▁</td></tr><tr><td>learning_rate</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_accuracy</td><td>47.2951</td></tr><tr><td>epoch</td><td>1</td></tr><tr><td>epoch_time</td><td>133.56668</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>train_accuracy</td><td>36.60612</td></tr><tr><td>train_loss</td><td>1.616</td></tr><tr><td>val_accuracy</td><td>47.2951</td></tr><tr><td>val_loss</td><td>1.40036</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Augmentation_no_augmentation</strong> at: <a href='https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition/runs/zqqj8ddj' target=\"_blank\">https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition/runs/zqqj8ddj</a><br> View project at: <a href='https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition' target=\"_blank\">https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_185648-zqqj8ddj/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best validation accuracy: 47.30%\n",
            "\n",
            "Testing augmentation strategy: basic_augmentation\n",
            "Description: Basic: Flip + Rotation\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_185907-q41s1o7y</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition/runs/q41s1o7y' target=\"_blank\">Augmentation_basic_augmentation</a></strong> to <a href='https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition' target=\"_blank\">https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition/runs/q41s1o7y' target=\"_blank\">https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition/runs/q41s1o7y</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting CNN training for 1 epochs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 314/314 [02:00<00:00,  2.60it/s, Loss=1.4393, Acc=34.81%]\n",
            "Validation: 100%|██████████| 68/68 [00:12<00:00,  5.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1:\n",
            "  Train Loss: 1.6461, Train Acc: 34.81%\n",
            "  Val Loss: 1.4472, Val Acc: 43.51%\n",
            "  LR: 0.001000, Time: 133.41s\n",
            "--------------------------------------------------\n",
            "Loaded best model with validation accuracy: 43.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>epoch_time</td><td>▁</td></tr><tr><td>learning_rate</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_accuracy</td><td>43.51056</td></tr><tr><td>epoch</td><td>1</td></tr><tr><td>epoch_time</td><td>133.40853</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>train_accuracy</td><td>34.81463</td></tr><tr><td>train_loss</td><td>1.64612</td></tr><tr><td>val_accuracy</td><td>43.51056</td></tr><tr><td>val_loss</td><td>1.4472</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Augmentation_basic_augmentation</strong> at: <a href='https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition/runs/q41s1o7y' target=\"_blank\">https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition/runs/q41s1o7y</a><br> View project at: <a href='https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition' target=\"_blank\">https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_185907-q41s1o7y/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best validation accuracy: 43.51%\n",
            "\n",
            "Testing augmentation strategy: advanced_augmentation\n",
            "Description: Advanced: Flip + Rotation + Brightness + Noise\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_190123-biddoysx</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition/runs/biddoysx' target=\"_blank\">Augmentation_advanced_augmentation</a></strong> to <a href='https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition' target=\"_blank\">https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition/runs/biddoysx' target=\"_blank\">https://wandb.ai/nipkha21-free-university-of-tbilisi-/facial-expression-recognition/runs/biddoysx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting CNN training for 1 epochs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   7%|▋         | 23/314 [00:10<02:14,  2.17it/s, Loss=1.7861, Acc=22.55%]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-3d9350706e54>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_patience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     augmentation_results[aug_name] = {\n",
            "\u001b[0;32m<ipython-input-10-fb69e78348c3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, early_stopping_patience)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mepoch_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-fb69e78348c3>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m                             )\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    242\u001b[0m             )\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    245\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    877\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    474\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OtNRp8MwpwXd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}